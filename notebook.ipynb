{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26b4b8dd",
   "metadata": {},
   "source": [
    "\n",
    "# TwiBot-22 — MiniLM-L12-v2 embeddings + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824f6d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, re, json, glob, math, time\n",
    "from datetime import datetime, timezone\n",
    "from dateutil import parser as dtparser\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "DATA_DIR = \"./data_processed\" \n",
    "TWEETS_GLOB = os.path.join(DATA_DIR, \"tweet_*_processed.json\")\n",
    "USER_JSON = os.path.join(DATA_DIR, \"user.json\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 512 \n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "RANDOM_STATE = 42\n",
    "N_TWEETS_PER_USER = 20  \n",
    "\n",
    "def log(msg: str):\n",
    "    print(f\"[{time.strftime('%H:%M:%S')}] {msg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a161e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_json_any(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        txt = f.read().strip()\n",
    "    try:\n",
    "        obj = json.loads(txt)\n",
    "        return obj\n",
    "    except json.JSONDecodeError:\n",
    "        rows = []\n",
    "        for line in txt.splitlines():\n",
    "            line=line.strip()\n",
    "            if not line: \n",
    "                continue\n",
    "            rows.append(json.loads(line))\n",
    "        return rows\n",
    "\n",
    "def tweets_to_df(tweet_obj):\n",
    "    if isinstance(tweet_obj, dict):\n",
    "        items = []\n",
    "        for tw_id, tw in tweet_obj.items():\n",
    "            rec = {'tweet_id': tw_id}\n",
    "            rec.update(tw)\n",
    "            items.append(rec)\n",
    "        return pd.DataFrame(items)\n",
    "    elif isinstance(tweet_obj, list):\n",
    "        return pd.DataFrame(tweet_obj)\n",
    "    else:\n",
    "        raise ValueError(\"Formato tweet JSON non riconosciuto.\")\n",
    "\n",
    "def users_to_df(user_obj):\n",
    "    if isinstance(user_obj, dict):\n",
    "        items = []\n",
    "        for uid, u in user_obj.items():\n",
    "            if isinstance(u, dict):\n",
    "                rec = {'_key': uid}\n",
    "                rec.update(u)\n",
    "                items.append(rec)\n",
    "        if items:\n",
    "            return pd.DataFrame(items)\n",
    "        else:\n",
    "            return pd.DataFrame([user_obj])\n",
    "    elif isinstance(user_obj, list):\n",
    "        return pd.DataFrame(user_obj)\n",
    "    else:\n",
    "        return pd.DataFrame([user_obj])\n",
    "\n",
    "def extract_numeric_from_user_id(uid):\n",
    "    if pd.isna(uid):\n",
    "        return np.nan\n",
    "    m = re.search(r'(\\d+)', str(uid))\n",
    "    return int(m.group(1)) if m else np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f5d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import ijson\n",
    "from datetime import datetime, timezone\n",
    "from dateutil import parser as dtparser\n",
    "import ijson \n",
    "import re \n",
    "from collections import defaultdict\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "user_obj = load_json_any(USER_JSON)\n",
    "users = users_to_df(user_obj)\n",
    "log(f\"Utenti caricati: {len(users)}\")\n",
    "\n",
    "if 'id' not in users.columns:\n",
    "    if '_key' in users.columns:\n",
    "        users['id'] = users['_key']\n",
    "    else:\n",
    "        users['id'] = None\n",
    "\n",
    "users['user_id_str'] = users['id'].astype(str)\n",
    "users['user_id_num'] = users['user_id_str'].apply(extract_numeric_from_user_id)\n",
    "\n",
    "if 'public_metrics' in users.columns:\n",
    "    pm = users['public_metrics'].apply(lambda x: x if isinstance(x, dict) else {})\n",
    "    pm_df = pd.json_normalize(pm)\n",
    "    before_cols = set(users.columns)\n",
    "    pm_df.columns = [f'pm.{c}' for c in pm_df.columns]\n",
    "    users = pd.concat([users.drop(columns=['public_metrics']), pm_df], axis=1)\n",
    "    added = set(users.columns) - before_cols\n",
    "\n",
    "def parse_dt_safe(x):\n",
    "    if pd.isna(x): return pd.NaT\n",
    "    try:\n",
    "        return dtparser.parse(str(x))\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "if 'created_at' in users.columns:\n",
    "    users['created_at_dt'] = users['created_at'].progress_apply(parse_dt_safe)\n",
    "    now = datetime.now(timezone.utc)\n",
    "    users['account_age_days'] = (now - users['created_at_dt']).dt.days\n",
    "    n_na = users['created_at_dt'].isna().sum()\n",
    "else:\n",
    "    users['account_age_days'] = np.nan\n",
    "    log(\"account_age_days=NaN\")\n",
    "\n",
    "def is_default_profile_img(url):\n",
    "    if not isinstance(url, str) or not url:\n",
    "        return True \n",
    "    return ('default_profile_images' in url) or ('default_profile' in url)\n",
    "\n",
    "if 'profile_image_url' in users.columns:\n",
    "    users['default_profile_image'] = users['profile_image_url'].progress_apply(is_default_profile_img)\n",
    "else:\n",
    "    log(\"default_profile_image=NaN\")\n",
    "    users['default_profile_image'] = pd.Series([np.nan]*len(users))\n",
    "\n",
    "\n",
    "tweet_files = sorted(glob.glob(TWEETS_GLOB))\n",
    "user_tweet_counts = defaultdict(int)\n",
    "filtered_tweets_data = []\n",
    "\n",
    "required_cols = [\n",
    "    'author_id', 'text', 'like_count', \n",
    "    'retweet_count', 'reply_count', 'quote_count'\n",
    "]\n",
    "\n",
    "for fp in tqdm(tweet_files, desc=\"Caricamento e filtro tweet\"):\n",
    "    log(f\"Processo: {os.path.basename(fp)}\")\n",
    "    try:\n",
    "        with open(fp, 'r', encoding='utf-8') as f:\n",
    "            parser = ijson.kvitems(f, '') \n",
    "            for tw_id, tw_data in tqdm(parser, desc=f\"Oggetti {os.path.basename(fp)}\", leave=False):\n",
    "                if not isinstance(tw_data, dict): \n",
    "                    continue\n",
    "                author_id = tw_data.get('author_id')\n",
    "                if not author_id or not isinstance(author_id, (int, float)):\n",
    "                    if isinstance(author_id, str):\n",
    "                        m = re.search(r'(\\d+)', str(author_id))\n",
    "                        author_id = int(m.group(1)) if m else None\n",
    "                    \n",
    "                    if not author_id:\n",
    "                        continue\n",
    "                author_id_int = int(author_id)\n",
    "                if user_tweet_counts[author_id_int] < N_TWEETS_PER_USER:\n",
    "                    user_tweet_counts[author_id_int] += 1\n",
    "                    record = {col: tw_data.get(col) for col in required_cols}\n",
    "                    record['author_id'] = author_id_int \n",
    "                    filtered_tweets_data.append(record)\n",
    "\n",
    "    except Exception as e:\n",
    "        if \"IncompleteJSONError\" in str(e) or \"JSONError\" in str(e):\n",
    "             log(f\"file {fp} corrotto\")\n",
    "\n",
    "\n",
    "tweets = pd.DataFrame(filtered_tweets_data)\n",
    "del filtered_tweets_data \n",
    "log(f\"Tweet totali: {len(tweets)}\")\n",
    "\n",
    "base_cols = ['author_id', 'text', 'like_count', 'retweet_count', 'reply_count', 'quote_count']\n",
    "for col in base_cols:\n",
    "    if col not in tweets.columns:\n",
    "        tweets[col] = np.nan\n",
    "        log(f\"{col}'=NaN\")\n",
    "\n",
    "print(f\"Utenti: {len(users)}  |  Tweet (filtrati): {len(tweets)}\")\n",
    "users.head(2), tweets.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c1539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "user_texts = defaultdict(list)\n",
    "user_stats = defaultdict(lambda: {\n",
    "    'like_sum': 0.0, \n",
    "    'retweet_sum': 0.0, \n",
    "    'reply_sum': 0.0, \n",
    "    'quote_sum': 0.0, \n",
    "    'count': 0,\n",
    "    'unique_texts': set() \n",
    "})\n",
    "\n",
    "\n",
    "for row in tqdm(tweets.itertuples(index=False), total=len(tweets), desc=\"Aggregazione manuale\"):\n",
    "    try:\n",
    "        author_id = int(row.author_id) \n",
    "        text = str(row.text) if pd.notna(row.text) else \"\"\n",
    "        \n",
    "        user_texts[author_id].append(text)\n",
    "        \n",
    "        stats = user_stats[author_id]\n",
    "        stats['count'] += 1\n",
    "        stats['unique_texts'].add(text)\n",
    "        \n",
    "        like_val = pd.to_numeric(row.like_count, errors='coerce')\n",
    "        retweet_val = pd.to_numeric(row.retweet_count, errors='coerce')\n",
    "        reply_val = pd.to_numeric(row.reply_count, errors='coerce')\n",
    "        quote_val = pd.to_numeric(row.quote_count, errors='coerce')\n",
    "\n",
    "        stats['like_sum'] += 0.0 if pd.isna(like_val) else like_val\n",
    "        stats['retweet_sum'] += 0.0 if pd.isna(retweet_val) else retweet_val\n",
    "        stats['reply_sum'] += 0.0 if pd.isna(reply_val) else reply_val\n",
    "        stats['quote_sum'] += 0.0 if pd.isna(quote_val) else quote_val\n",
    "        \n",
    "    except (TypeError, ValueError) as e:\n",
    "        continue\n",
    "\n",
    "del tweets\n",
    "agg_text_data = []\n",
    "for author_id, texts in tqdm(user_texts.items(), desc=\"Salvataggio liste testi\"):\n",
    "    agg_text_data.append({'author_id': author_id, 'tweets_list': texts})\n",
    "agg_text = pd.DataFrame(agg_text_data)\n",
    "del user_texts, agg_text_data \n",
    "\n",
    "eng_data = []\n",
    "for author_id, stats in tqdm(user_stats.items(), desc=\"Calcolo medie\"):\n",
    "    count = stats['count']\n",
    "    if count == 0: continue\n",
    "        \n",
    "    avg_like = stats['like_sum'] / count\n",
    "    avg_retweet = stats['retweet_sum'] / count\n",
    "    avg_reply = stats['reply_sum'] / count\n",
    "    avg_quote = stats['quote_sum'] / count\n",
    "    unique_ratio = len(stats['unique_texts']) / count\n",
    "    \n",
    "    eng_data.append({\n",
    "        'author_id': author_id,\n",
    "        'avg_like': avg_like,\n",
    "        'avg_retweet': avg_retweet,\n",
    "        'avg_reply': avg_reply,\n",
    "        'avg_quote': avg_quote,\n",
    "        'n_tweets': count,\n",
    "        'unique_text_ratio': unique_ratio\n",
    "    })\n",
    "eng = pd.DataFrame(eng_data)\n",
    "del user_stats, eng_data\n",
    "\n",
    "\n",
    "users_j = users.copy()\n",
    "users_j['user_id_num'] = pd.to_numeric(users_j['user_id_num'], errors='coerce')\n",
    "agg = users_j.merge(agg_text, left_on='user_id_num', right_on='author_id', how='left')\\\n",
    "             .merge(eng, left_on='user_id_num', right_on='author_id', how='left', suffixes=('','_eng'))\n",
    "\n",
    "for c in ['author_id_x','author_id_y']:\n",
    "    if c in agg.columns:\n",
    "        agg = agg.drop(columns=[c])\n",
    "\n",
    "for c in ['avg_like','avg_retweet','avg_reply','avg_quote','n_tweets','unique_text_ratio']:\n",
    "    if c in agg.columns:\n",
    "        agg[c] = agg[c].fillna(0.0)\n",
    "\n",
    "if 'description' not in agg.columns:\n",
    "    agg['description'] = \"\"\n",
    "    \n",
    "print(f\"Righe finali: {len(agg)}\")\n",
    "agg.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a24e72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_label(x):\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)): \n",
    "        return np.nan\n",
    "    xs = str(x).strip().lower()\n",
    "    if xs in {'bot','1','true','yes','fake','ai','automated'}:\n",
    "        return 1\n",
    "    if xs in {'human','0','false','no','real','genuine'}:\n",
    "        return 0\n",
    "    return np.nan\n",
    "\n",
    "labels = None\n",
    "\n",
    "lbl_csv_path = os.path.join(DATA_DIR, 'label.csv')\n",
    "if os.path.exists(lbl_csv_path):\n",
    "    try:\n",
    "        tmp = pd.read_csv(lbl_csv_path, header=None, names=['user_id_str', 'label'])\n",
    "        tmp['y'] = tmp['label'].apply(normalize_label)\n",
    "        labels = tmp[['user_id_str','y']]\n",
    "        log(f\"Caricati {len(labels)} record\")\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "\n",
    "if labels is None and 'label' in users.columns:\n",
    "    tmp = users[['user_id_str','label']].copy()\n",
    "    tmp['y'] = tmp['label'].apply(normalize_label)\n",
    "    labels = tmp[['user_id_str','y']]\n",
    "\n",
    "elif labels is None:\n",
    "    lbl_path = os.path.join(DATA_DIR, 'label.json')\n",
    "    if os.path.exists(lbl_path):\n",
    "        lbl_obj = load_json_any(lbl_path)\n",
    "        if isinstance(lbl_obj, dict):\n",
    "            tmp = pd.DataFrame({'user_id_str': list(lbl_obj.keys()), 'label': list(lbl_obj.values())})\n",
    "        elif isinstance(lbl_obj, list):\n",
    "            tmp = pd.DataFrame(lbl_obj)\n",
    "            if 'user_id' in tmp.columns and 'label' in tmp.columns:\n",
    "                tmp = tmp.rename(columns={'user_id':'user_id_str'})\n",
    "        else:\n",
    "            tmp = pd.DataFrame()\n",
    "        if len(tmp):\n",
    "            tmp['y'] = tmp['label'].apply(normalize_label)\n",
    "            labels = tmp[['user_id_str','y']]\n",
    "\n",
    "if labels is None:\n",
    "    gt_path = os.path.join(DATA_DIR, 'ground_truth.json')\n",
    "    if os.path.exists(gt_path):\n",
    "        gt_obj = load_json_any(gt_path)\n",
    "        if isinstance(gt_obj, dict):\n",
    "            tmp = pd.DataFrame({'user_id_str': list(gt_obj.keys()), 'label': list(gt_obj.values())})\n",
    "            tmp['y'] = tmp['label'].apply(normalize_label)\n",
    "            labels = tmp[['user_id_str','y']]\n",
    "\n",
    "if labels is not None:\n",
    "    data = agg.merge(labels, on='user_id_str', how='inner')\n",
    "    data = data[~data['y'].isna()].reset_index(drop=True)\n",
    "    \n",
    "    if len(data) > 0:\n",
    "        print(data['y'].value_counts(normalize=True).to_string())\n",
    "else:\n",
    "    data = agg.copy()\n",
    "    \n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1898947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "EMBEDDING_DIM = 384\n",
    "\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    model = AutoModel.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "except Exception as e:\n",
    "    raise e\n",
    "\n",
    "\n",
    "def get_bert_embeddings(texts: list, batch_size: int) -> np.ndarray:\n",
    "    \n",
    "    all_embeddings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i : i + batch_size]\n",
    "            \n",
    "            inputs = tokenizer(\n",
    "                batch_texts, \n",
    "                return_tensors=\"pt\",\n",
    "                padding=True, \n",
    "                truncation=True, \n",
    "                max_length=MAX_LENGTH\n",
    "            )\n",
    "            inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "            outputs = model(**inputs)\n",
    "            hidden_states = outputs.last_hidden_state\n",
    "            mask = inputs['attention_mask']\n",
    "            mask_expanded = mask.unsqueeze(-1).expand(hidden_states.size())\n",
    "            masked_outputs = hidden_states * mask_expanded\n",
    "            sum_embeddings = torch.sum(masked_outputs, 1)\n",
    "            count_safe = torch.clamp(mask.sum(1, keepdim=True), min=1e-9)\n",
    "            mean_embeddings = sum_embeddings / count_safe\n",
    "            mean_embeddings = torch.nn.functional.normalize(mean_embeddings, p=2, dim=1)\n",
    "            all_embeddings.append(mean_embeddings.cpu().numpy())\n",
    "    \n",
    "    if not all_embeddings:\n",
    "        return np.array([]).reshape(0, EMBEDDING_DIM)\n",
    "        \n",
    "    return np.vstack(all_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0140e7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "BIO_EMBEDDINGS_PATH = os.path.join(DATA_DIR, \"precalc_bio_embeddings.parquet\")\n",
    "\n",
    "\n",
    "if os.path.exists(BIO_EMBEDDINGS_PATH):\n",
    "    try:\n",
    "        bio_df = pd.read_parquet(BIO_EMBEDDINGS_PATH)\n",
    "        \n",
    "        if bio_df.shape[0] == len(data) and bio_df.shape[1] == EMBEDDING_DIM:\n",
    "            bio_df.index = data.index\n",
    "        else:\n",
    "            bio_df = None\n",
    "            \n",
    "    except Exception as e:\n",
    "        bio_df = None\n",
    "else:\n",
    "    log(\"Nessun file precalcolato trovato\")\n",
    "    bio_df = None\n",
    "\n",
    "if bio_df is None:\n",
    "    bio_texts = data['description'].fillna(\"\").tolist()\n",
    "    bio_embeddings = get_bert_embeddings(bio_texts, BATCH_SIZE)\n",
    "\n",
    "    log(f\"Shape: {bio_embeddings.shape}\")\n",
    "\n",
    "    bio_df = pd.DataFrame(\n",
    "        bio_embeddings, \n",
    "        index=data.index, \n",
    "        columns=[f'bio_e_{i}' for i in range(EMBEDDING_DIM)]\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        log(f\"Salvataggio embedding in {BIO_EMBEDDINGS_PATH}...\")\n",
    "        bio_df.to_parquet(BIO_EMBEDDINGS_PATH, index=True)\n",
    "    except Exception as e:\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3826c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "\n",
    "TWEET_EMBEDDINGS_PATH = os.path.join(DATA_DIR, \"precalc_tweet_avg_embeddings.csv\")\n",
    "\n",
    "\n",
    "if os.path.exists(TWEET_EMBEDDINGS_PATH):\n",
    "    try:\n",
    "        tweet_df = pd.read_csv(TWEET_EMBEDDINGS_PATH)\n",
    "        tweet_df = tweet_df.set_index('original_index')\n",
    "        \n",
    "        if tweet_df.shape[0] == len(data) and tweet_df.shape[1] == EMBEDDING_DIM:\n",
    "            tweet_df.index = data.index\n",
    "        else:\n",
    "            tweet_df = None \n",
    "            \n",
    "    except Exception as e:\n",
    "        tweet_df = None\n",
    "else:\n",
    "    log(\"Nessun file trovato\")\n",
    "    tweet_df = None\n",
    "\n",
    "if tweet_df is None:\n",
    "    \n",
    "    if os.path.exists(TWEET_EMBEDDINGS_PATH):\n",
    "        try:\n",
    "            os.remove(TWEET_EMBEDDINGS_PATH)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    col_names = ['original_index'] + [f'tweet_e_{i}' for i in range(EMBEDDING_DIM)]\n",
    "    try:\n",
    "        pd.DataFrame(columns=col_names).to_csv(TWEET_EMBEDDINGS_PATH, index=False)\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "    for idx, row in tqdm(data.iterrows(), total=len(data), desc=\"Embedding e Salvataggio 1-per-1\"):\n",
    "        tweet_list = row.get('tweets_list')\n",
    "        \n",
    "        texts_to_embed = []\n",
    "        if isinstance(tweet_list, list):\n",
    "            for t in tweet_list:\n",
    "                if pd.notna(t) and str(t).strip():\n",
    "                    texts_to_embed.append(str(t))\n",
    "\n",
    "        if not texts_to_embed:\n",
    "            avg_embedding = np.zeros(EMBEDDING_DIM)\n",
    "        else:\n",
    "            try:\n",
    "                user_embeddings = get_bert_embeddings(texts_to_embed, BATCH_SIZE)\n",
    "                \n",
    "                if user_embeddings.shape[0] > 0:\n",
    "                    avg_embedding = np.mean(user_embeddings, axis=0)\n",
    "                else:\n",
    "                    avg_embedding = np.zeros(EMBEDDING_DIM)\n",
    "            except Exception as e:\n",
    "                avg_embedding = np.zeros(EMBEDDING_DIM)\n",
    "                raise e\n",
    "                \n",
    "        \n",
    "        record = {f'tweet_e_{i}': val for i, val in enumerate(avg_embedding)}\n",
    "        record['original_index'] = idx\n",
    "        \n",
    "        row_df = pd.DataFrame([record], columns=col_names)\n",
    "        \n",
    "        try:\n",
    "            row_df.to_csv(TWEET_EMBEDDINGS_PATH, mode='a', header=False, index=False)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    try:\n",
    "        tweet_df = pd.read_csv(TWEET_EMBEDDINGS_PATH)\n",
    "        tweet_df = tweet_df.set_index('original_index')\n",
    "        tweet_df = tweet_df.reindex(data.index, fill_value=0.0) \n",
    "    except Exception as e:\n",
    "        empty_cols = [f'tweet_e_{i}' for i in range(EMBEDDING_DIM)]\n",
    "        tweet_df = pd.DataFrame(np.zeros((len(data), EMBEDDING_DIM)), index=data.index, columns=empty_cols)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb5be2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "structural_features_cols = [\n",
    "    'pm.followers_count', \n",
    "    'pm.following_count', \n",
    "    'pm.listed_count', \n",
    "    'pm.tweet_count',\n",
    "    'account_age_days', \n",
    "    'default_profile_image', \n",
    "    'protected',             \n",
    "    'avg_like', \n",
    "    'avg_retweet', \n",
    "    'avg_reply', \n",
    "    'avg_quote', \n",
    "    'n_tweets', \n",
    "    'unique_text_ratio'\n",
    "]\n",
    "\n",
    "if 'verified' in data.columns:\n",
    "    structural_features_cols.append('verified')\n",
    "\n",
    "existing_structural_cols = [c for c in structural_features_cols if c in data.columns]\n",
    "\n",
    "X_struct = data[existing_structural_cols].copy()\n",
    "\n",
    "for col in ['default_profile_image', 'protected', 'verified']:\n",
    "    if col in X_struct.columns:\n",
    "        X_struct[col] = X_struct[col].astype(int)\n",
    "\n",
    "X_struct = X_struct.fillna(0.0)\n",
    "\n",
    "X_struct.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf3206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_full = pd.concat([X_struct, bio_df, tweet_df], axis=1)\n",
    "y = data['y'].astype(int)\n",
    "\n",
    "X_full.columns = X_full.columns.astype(str).str.replace(r'[\\\\\\\",\\\\\\\\[\\\\\\\\]<>]', '_', regex=True)\n",
    "\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X_full, y,\n",
    "    test_size=0.2,                \n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y                    \n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val,\n",
    "    test_size=0.25,               \n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_train_val          \n",
    ")\n",
    "\n",
    "log(f\"Train shapes: X={X_train.shape}, y={y_train.shape}\")\n",
    "log(f\"Validation shapes: X={X_val.shape}, y={y_val.shape}\") \n",
    "log(f\"Test shapes: X={X_test.shape}, y={y_test.shape}\") \n",
    "\n",
    "log(f\"Distribuzione 'bot' in y_train: {y_train.mean():.2%}\")\n",
    "log(f\"Distribuzione 'bot' in y_val:   {y_val.mean():.2%}\") \n",
    "log(f\"Distribuzione 'bot' in y_test:  {y_test.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8887f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "\n",
    "try:\n",
    "    counts = y_train.value_counts()\n",
    "    scale_pos_weight = counts[0] / counts[1]\n",
    "except KeyError:\n",
    "    scale_pos_weight = 1.0\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    tree_method='hist',\n",
    "    early_stopping_rounds=30\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)], \n",
    "    verbose=100                \n",
    ")\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235bad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "MODEL_SAVE_PATH = os.path.join(DATA_DIR, \"xgb_model_trained.joblib\")\n",
    "log(f\"Salvataggio del modello in: {MODEL_SAVE_PATH}\")\n",
    "try:\n",
    "    joblib.dump(xgb_model, MODEL_SAVE_PATH)\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7473c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score, classification_report, confusion_matrix,\n",
    "    precision_recall_curve, average_precision_score, balanced_accuracy_score,\n",
    "    matthews_corrcoef, cohen_kappa_score, brier_score_loss, roc_curve\n",
    ")\n",
    "import xgboost as xgb\n",
    "\n",
    "def expected_calibration_error(y_true, y_prob, n_bins=10):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_prob = np.asarray(y_prob)\n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    ece = 0.0\n",
    "    for i in range(n_bins):\n",
    "        lo, hi = bins[i], bins[i+1]\n",
    "        mask = (y_prob >= lo) & (y_prob < hi) if i < n_bins - 1 else (y_prob >= lo) & (y_prob <= hi)\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "        bin_acc = y_true[mask].mean()                    \n",
    "        bin_conf = y_prob[mask].mean()                   \n",
    "        ece += (mask.mean()) * abs(bin_conf - bin_acc)   \n",
    "    return ece\n",
    "\n",
    "def plot_confusion_matrix(cm, labels=('Human','Bot'), normalize=False, title='Confusion Matrix'):\n",
    "    if normalize:\n",
    "        with np.errstate(all='ignore'):\n",
    "            cm_norm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "            cm_to_plot = np.nan_to_num(cm_norm)\n",
    "    else:\n",
    "        cm_to_plot = cm\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    im = ax.imshow(cm_to_plot, interpolation='nearest')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_xticks([0,1]); ax.set_xticklabels([f'Pred {labels[0]}', f'Pred {labels[1]}'])\n",
    "    ax.set_yticks([0,1]); ax.set_yticklabels([f'True {labels[0]}', f'True {labels[1]}'])\n",
    "\n",
    "\n",
    "    for i in range(cm_to_plot.shape[0]):\n",
    "        for j in range(cm_to_plot.shape[1]):\n",
    "            txt = f'{cm_to_plot[i, j]:.2f}' if normalize else f'{int(cm_to_plot[i, j])}'\n",
    "            ax.text(j, i, txt, ha='center', va='center')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def metrics_at_threshold(y_true, y_prob, thr):\n",
    "    y_hat = (y_prob >= thr).astype(int)\n",
    "    acc = accuracy_score(y_true, y_hat)\n",
    "    f1b = f1_score(y_true, y_hat, pos_label=1)\n",
    "    cm = confusion_matrix(y_true, y_hat)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    tpr = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "    fpr = fp / (fp + tn) if (fp + tn) else 0.0\n",
    "    precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "    spec = tn / (tn + fp) if (tn + fp) else 0.0\n",
    "    bal_acc = balanced_accuracy_score(y_true, y_hat)\n",
    "    mcc = matthews_corrcoef(y_true, y_hat)\n",
    "    kappa = cohen_kappa_score(y_true, y_hat)\n",
    "    rate_flagged = (y_hat.mean())  # fraction of accounts flagged as bot\n",
    "    return {\n",
    "        'threshold': thr, 'accuracy': acc, 'f1_bot': f1b, 'precision': precision,\n",
    "        'recall_bot': tpr, 'specificity': spec, 'fpr': fpr, 'balanced_acc': bal_acc,\n",
    "        'mcc': mcc, 'kappa': kappa, 'flagged_rate': rate_flagged, 'cm': cm\n",
    "    }\n",
    "\n",
    "\n",
    "def bootstrap_ci(y_true, y_prob, y_hat, n_boot=1000, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(y_true)\n",
    "    accs, f1s, auprs = [], [], []\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
    "    aupr_full = average_precision_score(y_true, y_prob)  \n",
    "\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.integers(0, n, n)\n",
    "        yt = y_true[idx]\n",
    "        yp = y_prob[idx]\n",
    "        yh = y_hat[idx]\n",
    "        accs.append(accuracy_score(yt, yh))\n",
    "        f1s.append(f1_score(yt, yh, pos_label=1))\n",
    "        auprs.append(average_precision_score(yt, yp))\n",
    "    def ci(a):\n",
    "        lo, hi = np.percentile(a, [2.5, 97.5])\n",
    "        return float(np.mean(a)), float(lo), float(hi)\n",
    "    return {'accuracy': ci(accs), 'f1_bot': ci(f1s), 'aupr': ci(auprs)}\n",
    "\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)                      \n",
    "y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]    \n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1_bot = f1_score(y_test, y_pred, pos_label=1)\n",
    "auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "aupr = average_precision_score(y_test, y_pred_proba)\n",
    "bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "tpr = tp / (tp + fn) if (tp + fn) else 0.0              \n",
    "spec = tn / (tn + fp) if (tn + fp) else 0.0             \n",
    "fpr_base = fp / (fp + tn) if (fp + tn) else 0.0\n",
    "brier = brier_score_loss(y_test, y_pred_proba)\n",
    "ece = expected_calibration_error(y_test, y_pred_proba, n_bins=10)\n",
    "\n",
    "log(\"--- Metriche sul Test Set ---\")\n",
    "log(f\"Accuracy:         {accuracy:.4f}\")\n",
    "log(f\"F1 Score (Bot):   {f1_bot:.4f}\")\n",
    "log(f\"AUC-ROC:          {auc_roc:.4f}\")\n",
    "log(f\"AUCPR (Bot):      {aupr:.4f}\")\n",
    "log(f\"Balanced Acc:     {bal_acc:.4f}\")\n",
    "log(f\"Specificity (TNR):{spec:.4f}\")\n",
    "log(f\"MCC:              {mcc:.4f}\")\n",
    "log(f\"Cohen's kappa:    {kappa:.4f}\")\n",
    "log(f\"Brier score:      {brier:.4f}\")\n",
    "log(f\"ECE (10 bins):    {ece:.4f}\")\n",
    "\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Human (0)', 'Bot (1)']))\n",
    "\n",
    "print(\"\\n--- Confusion Matrix (counts) ---\")\n",
    "print(cm)\n",
    "plot_confusion_matrix(cm, labels=('Human','Bot'), normalize=False, title='Confusion Matrix (counts)')\n",
    "plot_confusion_matrix(cm, labels=('Human','Bot'), normalize=True,  title='Confusion Matrix (row-normalized)')\n",
    "\n",
    "\n",
    "fpr, tpr_curve, roc_thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr_curve)\n",
    "\n",
    "fig = plt.figure(figsize=(5,4))\n",
    "plt.plot(fpr, tpr_curve, label=f'ROC (AUC={roc_auc:.3f})')\n",
    "plt.plot([0,1],[0,1], linestyle='--')\n",
    "plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (Bot = positive)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "precision, recall, pr_thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "aupr_viz = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "fig = plt.figure(figsize=(5,4))\n",
    "plt.plot(recall, precision, label=f'PR (AP={aupr_viz:.3f})')\n",
    "plt.xlabel('Recall (Bot)'); plt.ylabel('Precision (Bot)')\n",
    "plt.title('Precision–Recall Curve (Bot = positive)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "n_bins = 10\n",
    "bins = np.linspace(0.0, 1.0, n_bins+1)\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2.0\n",
    "emp_acc = []\n",
    "avg_conf = []\n",
    "for i in range(n_bins):\n",
    "    lo, hi = bins[i], bins[i+1]\n",
    "    mask = (y_pred_proba >= lo) & (y_pred_proba < hi) if i < n_bins - 1 else (y_pred_proba >= lo) & (y_pred_proba <= hi)\n",
    "    if np.any(mask):\n",
    "        emp_acc.append(y_test[mask].mean())\n",
    "        avg_conf.append(y_pred_proba[mask].mean())\n",
    "    else:\n",
    "        emp_acc.append(np.nan)\n",
    "        avg_conf.append(np.nan)\n",
    "\n",
    "emp_acc = np.array(emp_acc); avg_conf = np.array(avg_conf)\n",
    "\n",
    "fig = plt.figure(figsize=(5,4))\n",
    "plt.plot([0,1],[0,1], linestyle='--', label='Perfect calibration')\n",
    "plt.plot(avg_conf, emp_acc, marker='o', label=f'Reliability (ECE={ece:.3f})')\n",
    "plt.xlim(0,1); plt.ylim(0,1)\n",
    "plt.xlabel('Mean predicted probability (Bot)')\n",
    "plt.ylabel('Empirical bot frequency')\n",
    "plt.title('Reliability Diagram')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def closest_idx(arr, target):\n",
    "    return int(np.argmin(np.abs(arr - target)))\n",
    "\n",
    "\n",
    "idx_1 = closest_idx(fpr, 0.01)\n",
    "idx_5 = closest_idx(fpr, 0.05)\n",
    "\n",
    "thr_1 = roc_thresholds[idx_1]\n",
    "thr_5 = roc_thresholds[idx_5]\n",
    "\n",
    "op_1 = metrics_at_threshold(y_test, y_pred_proba, thr_1)\n",
    "op_5 = metrics_at_threshold(y_test, y_pred_proba, thr_5)\n",
    "\n",
    "\n",
    "def precision_at_recall(target_recall):\n",
    "    idxs = np.where(recall >= target_recall)[0]\n",
    "    if len(idxs) == 0:\n",
    "        return None\n",
    "    i = idxs[-1] if idxs[-1] < len(pr_thresholds) else len(pr_thresholds)-1\n",
    "    thr = pr_thresholds[i] if i < len(pr_thresholds) else 0.5\n",
    "    return metrics_at_threshold(y_test, y_pred_proba, thr)\n",
    "\n",
    "op_pr70 = precision_at_recall(0.70)\n",
    "op_pr80 = precision_at_recall(0.80)\n",
    "\n",
    "def recall_at_precision(target_precision):\n",
    "    idxs = np.where(precision >= target_precision)[0]\n",
    "    if len(idxs) == 0:\n",
    "        return None\n",
    "    i = idxs[0]\n",
    "    thr = pr_thresholds[i-1] if i-1 >= 0 else pr_thresholds[0]\n",
    "    return metrics_at_threshold(y_test, y_pred_proba, thr)\n",
    "\n",
    "op_p95 = recall_at_precision(0.95)\n",
    "\n",
    "print(\"\\n--- Operating Points ---\")\n",
    "def pretty(op, name):\n",
    "    per10k = int(round(op['flagged_rate'] * 10000))\n",
    "    print(f\"{name}: thr={op['threshold']:.4f} | Prec={op['precision']:.3f} | Rec={op['recall_bot']:.3f} | FPR={op['fpr']:.3f} | MCC={op['mcc']:.3f} | Flagged≈{per10k}/10k\")\n",
    "\n",
    "pretty(op_1,  \"TPR @ FPR=1%\")\n",
    "pretty(op_5,  \"TPR @ FPR=5%\")\n",
    "pretty(op_pr70, \"Precision @ Recall=0.70\")\n",
    "pretty(op_pr80, \"Precision @ Recall=0.80\")\n",
    "pretty(op_p95,  \"Recall @ Precision=0.95\")\n",
    "\n",
    "\n",
    "booster = xgb_model.get_booster()\n",
    "\n",
    "raw_imp = booster.get_score(importance_type='gain')  \n",
    "\n",
    "feat_names = getattr(xgb_model, \"feature_names_in_\", None)\n",
    "if feat_names is None:\n",
    "    feat_names = list(X.columns)\n",
    "\n",
    "if raw_imp and next(iter(raw_imp)).startswith(\"f\"):\n",
    "    mapped = {}\n",
    "    for k, v in raw_imp.items():\n",
    "        idx = int(k[1:]) if k[1:].isdigit() else None\n",
    "        mapped[feat_names[idx] if idx is not None and idx < len(feat_names) else k] = v\n",
    "    raw_imp = mapped\n",
    "\n",
    "s = pd.Series(raw_imp, dtype=\"float64\")\n",
    "s = s.reindex(list(feat_names), fill_value=0.0)\n",
    "\n",
    "pat_tweet = re.compile(r\"^tweet(?:_e)?_\\d+$\") \n",
    "pat_bio   = re.compile(r\"^bio(?:_e)?_\\d+$\")\n",
    "\n",
    "def group_name(name: str) -> str:\n",
    "    if pat_tweet.match(name):\n",
    "        return \"tweet\"\n",
    "    if pat_bio.match(name):\n",
    "        return \"bio\"\n",
    "    return name \n",
    "\n",
    "g = (\n",
    "    s.groupby([group_name])\n",
    "     .mean()                \n",
    "     .sort_values(ascending=False)\n",
    "     .head(30)\n",
    ")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "g.iloc[::-1].plot(kind=\"barh\", ax=ax)\n",
    "ax.set_title(\"Feature Importance (media per embedding) — Top 30\")\n",
    "ax.set_xlabel(\"Gain\")\n",
    "ax.set_ylabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "DO_BOOTSTRAP = False\n",
    "if DO_BOOTSTRAP:\n",
    "    log(\"Bootstrap CI (potrebbe richiedere tempo)...\")\n",
    "    ci = bootstrap_ci(np.asarray(y_test), np.asarray(y_pred_proba), np.asarray(y_pred), n_boot=1000, seed=42)\n",
    "    print(\"\\n--- Bootstrap 95% CI ---\")\n",
    "    print(f\"Accuracy:  mean={ci['accuracy'][0]:.4f}  95%CI=({ci['accuracy'][1]:.4f}, {ci['accuracy'][2]:.4f})\")\n",
    "    print(f\"F1(bot):   mean={ci['f1_bot'][0]:.4f}   95%CI=({ci['f1_bot'][1]:.4f}, {ci['f1_bot'][2]:.4f})\")\n",
    "    print(f\"AUCPR:     mean={ci['aupr'][0]:.4f}    95%CI=({ci['aupr'][1]:.4f}, {ci['aupr'][2]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41bafe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
